{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip, binascii, struct, numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the classifier to recognize both MNIST numbers and NON-MNIST letters. Our training plan is approximately as follows:\n",
    "1) Load mnist data\n",
    "2) Load non-mnist data\n",
    "3) Merge both data sources into a single array\n",
    "4) Merge their label into a single array\n",
    "5) Split each training data set training and test.\n",
    "5.1) Merge training data sets for both mnist and non-mnist\n",
    "5.2) Merge test datasets\n",
    "5.3) Add \"empty\" training set\n",
    "5.4) Add \"empty\" test set\n",
    "6) Build Tensorf-flow model\n",
    "7) Train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = 'mnist'\n",
    "train_data_filename = directory + '/train-images-idx3-ubyte.gz'\n",
    "train_labels_filename = directory + '/train-labels-idx1-ubyte.gz'\n",
    "test_data_filename = directory + '/t10k-images-idx3-ubyte.gz'\n",
    "test_labels_filename = directory + '/t10k-labels-idx1-ubyte.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST dataset\n",
    " Extract the images into a 4D tensor [image index, y, x, channels]. For greyscale MNIST, the number of channels is always 1. Values are rescaled from [0, 255] down to [-0.5, 0.5]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_SIZE = 28\n",
    "PIXEL_DEPTH = 255\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "  print ('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    # Skip the magic number and dimensions; we know these values.\n",
    "    bytestream.read(16)\n",
    "    \n",
    "    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images)\n",
    "    data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "    data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "    return data\n",
    "\n",
    "train_data = extract_data(train_data_filename, 60000)\n",
    "test_data = extract_data(test_data_filename, 10000)\n",
    "train_data.shape\n",
    "#plt.imshow(train_data[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load MNIST labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "Training labels shape (60000, 20)\n",
      "First label vector [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "Second label vector [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "NUM_LABELS = 20\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "  \"\"\"Extract the labels into a 1-hot matrix [image index, label index].\"\"\"\n",
    "  print ('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    # Skip the magic number and count; we know these values.\n",
    "    bytestream.read(8)\n",
    "    \n",
    "    buf = bytestream.read(1 * num_images)\n",
    "    labels = numpy.frombuffer(buf, dtype=numpy.uint8)\n",
    "  # Convert to dense 1-hot representation.\n",
    "  return (numpy.arange(NUM_LABELS) == labels[:, None]).astype(numpy.float32)\n",
    "\n",
    "train_labels = extract_labels(train_labels_filename, 60000)\n",
    "test_labels = extract_labels(test_labels_filename, 10000)\n",
    "print ('Training labels shape', train_labels.shape)\n",
    "print ('First label vector', train_labels[0])\n",
    "print ('Second label vector', train_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training data into 2 sets: training , validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation shape (5000, 28, 28, 1)\n",
      "Train size 55000\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_SIZE = 5000\n",
    "\n",
    "validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "print ('Validation shape', validation_data.shape)\n",
    "print ('Train size', train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NON-MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = directory + '/notMNIST.pickle'\n",
    "f = open(pickle_file, 'rb')\n",
    "data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "nm_train_data = data['train_dataset']\n",
    "nm_train_labels = data['train_labels']\n",
    "\n",
    "nm_valid_data = data['valid_dataset']\n",
    "nm_valid_labels = data['valid_labels']\n",
    "\n",
    "nm_test_dataset = data['test_dataset']\n",
    "nm_test_labels = data['test_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape data array to match that of MNIST. Currently it's [N, h, w]. We want [N, h, w, channels], where in this case the channels == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nm_train_data = nm_train_data.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shift labels by 10. The first 10 indexes are for MNIST numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shift_by = 10\n",
    "nm_train_labels_real_adj = nm_train_labels + shift_by\n",
    "nm_valid_labels_adj = nm_valid_labels + shift_by\n",
    "nm_test_labels_adj = nm_test_labels + shift_by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels into one-hot encoding similar to MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_one_hot(real_labels):\n",
    "    return (numpy.arange(NUM_LABELS) == real_labels[:, None]).astype(np.float32)\n",
    "nm_train_labels = to_one_hot(nm_train_labels_real_adj)\n",
    "nm_valid_labels = to_one_hot(nm_valid_labels_adj)\n",
    "nm_test_labels = to_one_hot(nm_test_labels_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data and label arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
